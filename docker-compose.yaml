
services:
  vllm-instruct:
    image: vllm/vllm-openai:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    env_file:
      - .env.vllm
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "8005:8000"
    volumes:
      - huggingface_cache:/root/.cache/huggingface
      - ./models:/opt/models
    ipc: host
    command: >
      --model /opt/models/Qwen2.5-7B-Instruct-Q4_K_M.gguf
      --tokenizer Qwen/Qwen2.5-0.5B-Instruct-GGUF
      --load-format gguf
      --tensor-parallel-size 1
      --disable-sliding-window
      --max-model-len 10000
      --gpu-memory-utilization 0.98
      --enable-auto-tool-choice
      --tool-call-parser hermes

  frontend:
    build:
      dockerfile: Dockerfile
      context: .
    env_file:
      - .env
    ports:
      - "8501:8501"

  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: pwd

  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
    environment:
      QDRANT__STORAGE__PATH: /qdrant/storage
      QDRANT__STORAGE__MEMORY_LIMIT: 1000000000
      QDRANT__STORAGE__MAX_CONNECTIONS: 1000
    volumes:
      - qdrant_storage:/qdrant/storage

volumes:
  mongo_data:
  qdrant_storage:
  huggingface_cache: